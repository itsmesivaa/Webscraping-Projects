{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MarketSmith WebScraping Stock Evaluation Rating Details, Quarterly Earnings Details for Every Stocks using Selenium and Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the StringIO module.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import the requests library \n",
    "import requests\n",
    "\n",
    "# Importing the StringIO module.\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Inserting stock data into SQL database using sqlachemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Defining headers with User agent to establish requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
    "'X-Requested-With': 'XMLHttpRequest'\n",
    "}\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function to scrape Marketsmith stock fundamental data\n",
    "def marketsmith_scrape(stock_list):\n",
    "    \n",
    "    for x in tqdm(range(0,len(stock_list))):\n",
    "        time.sleep(2)\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "\n",
    "        #Firefox browser webdriver\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "\n",
    "        #Google chrome webdriver\n",
    "        #options = webdriver.ChromeOptions()\n",
    "        #driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        #Base Url to fetch stock fundamental data through request\n",
    "        url = \"https://marketsmithindia.com/mstool/eval/{}/evaluation.jsp#/\".format(stock_list[x])\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "\n",
    "        #Populating stock ratings data for individual stocks from Marketsmith evaluation pages\n",
    "        #Populating stock ownership institution details for individual stocks from Marketsmith evaluation pages\n",
    "        if x==0:\n",
    "            stock_detail_header = soup.find_all('div', class_ = \"details\")\n",
    "            \n",
    "        \n",
    "        #Stock Ownership & Institution Details - START\n",
    "        stock_ownership_header = soup.find('table', \\\n",
    "                    class_ = \"table table-condensed tableDetails managementTablefont removeTableMargin\", \\\n",
    "                    id = \"chartTable\")\n",
    "        \n",
    "        ownership_header_object = stock_ownership_header.find_all('th')\n",
    "        #Iterating ownership headers by element to add into list for further processing\n",
    "        #Not iterating all rows because last rows is NULL\n",
    "        stock_ownership_institution_headers = [ head.text.strip() for head in ownership_header_object ]\n",
    "        stock_ownership_institution_headers.insert(0,\"Stock Name\")\n",
    "        print('Institution Details<<<<<<<<<<Final Stock Institution Headers',stock_ownership_institution_headers)\n",
    "        \n",
    "        #Filtering data contents for stock ownership details\n",
    "        stock_ownership_header_rows = stock_ownership_header.find_all('tr')\n",
    "        \n",
    "        #Creating final Data frame for quarterly earnings one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            df_temp_ownership = pd.DataFrame(columns= stock_ownership_institution_headers)\n",
    "            \n",
    "            print(\"DF OwnershipColumns\",df_temp_ownership.columns)\n",
    "            \n",
    "            all_stocks_institutional_ownership = pd.DataFrame(columns= df_temp_ownership)\n",
    "            \n",
    "        print(\"Institution Ownership Dataframe\",all_stocks_institutional_ownership)\n",
    "        \n",
    "        #Iterating individual quarterly earnings table row by element to add into list for further processing\n",
    "        stock_institution_data = []\n",
    "        for data in stock_ownership_header_rows:\n",
    "            owner_row_data = data.find_all('td')\n",
    "            institution_data = [ q_data.text.strip() for q_data in owner_row_data]\n",
    "            #Adding Stock name to institution rows manually\n",
    "            institution_data.insert(0,stock_list[x])\n",
    "            \n",
    "            #Adding iterated institution data to list for a stock on their respective iteration of different quarters\n",
    "            stock_institution_data.append(institution_data)\n",
    "            \n",
    "            print(\"Stock Institution Data\",\"<<<<<>>>>>>\",institution_data)\n",
    "        #Removing NULL data from the list            \n",
    "        stock_institution_data.pop(0)\n",
    "        print(\"Final List\",\">><><><><><><><><>\",stock_institution_data)\n",
    "        \n",
    "        #Appending institution details rows stock specifically to dataframe \n",
    "        df_temp_ownership = pd.DataFrame(columns= stock_ownership_institution_headers, data = stock_institution_data)\n",
    "        all_stocks_institutional_ownership = all_stocks_institutional_ownership._append(df_temp_ownership, ignore_index=True)\n",
    "        \n",
    "        print(\"******Before Institutional Data for each Stocks Dataframe:******\",all_stocks_institutional_ownership)\n",
    "        # melt the dataframe to create a single column for Quarter\n",
    "        all_stocks_institutional_ownership_melted = pd.melt(all_stocks_institutional_ownership, id_vars=['Stock Name', 'Owner Name'], \\\n",
    "                                                    var_name='Quarter', value_name='Percentage')\n",
    "\n",
    "        # pivot the dataframe to create separate columns for each Owner Name\n",
    "        all_stocks_institutional_ownership_pivoted = all_stocks_institutional_ownership_melted.pivot_table(index=['Stock Name', 'Quarter'], \\\n",
    "                                                    columns='Owner Name', values='Percentage', aggfunc='first').reset_index()\n",
    "        \n",
    "        all_stocks_institutional_ownership_pivoted.columns = all_stocks_institutional_ownership_pivoted.columns.str.replace(' ','_', regex=True)\n",
    "        \n",
    "        print(\"******After Institutional Data for each Stocks Dataframe:******\", all_stocks_institutional_ownership_pivoted)\n",
    "        #Stock Ownership & Institution Details - END\n",
    "        \n",
    "        \n",
    "        #Stock Evalutation Ratings details-- START\n",
    "        cols = []        \n",
    "        #Generating columns through iteration for stock_detail_header\n",
    "        \n",
    "        for y in range(0,len(stock_detail_header)):\n",
    "            cols.append(stock_detail_header[y].get_text().strip())\n",
    "            \n",
    "        #Creating a new column for stock wise segregation\n",
    "        cols.insert(0,\"Stock Name\")\n",
    "        \n",
    "        print(y,\"columns\",\"--->>>\",cols)\n",
    "        \n",
    "        #Generating row values for the stock_detail_header header \n",
    "        stock_detail_value = soup.find_all('div', class_ = \"value\")\n",
    "        print(format(stock_list[x]),\"StockDetailValue>>>\",stock_detail_value) \n",
    "        \n",
    "\n",
    "        #Feeding an empty Dataframe with its respective column values through iterating summary_data list\n",
    "        #Creating an empty Dataframe to feed the column names through iterating summary_cols list\n",
    "\n",
    "        summary_data_values = []\n",
    "        \n",
    "\n",
    "        #Generating columns data through iteration\n",
    "        for z in range(0,len(stock_detail_value)):\n",
    "            print(stock_detail_value[z].get_text().strip())\n",
    "            summary_data_values.append(stock_detail_value[z].get_text().strip())\n",
    "        \n",
    "        #Checking if all data values were empty for a respective stock in Marketsmith by \n",
    "        #moving list into set to avoid duplicate values and see if it matches '' empty value\n",
    "        if ('' in (set(summary_data_values))):\n",
    "            print(\"########Stock Not PresentSummary Set values#########\", set(summary_data_values))\n",
    "            continue\n",
    "        \n",
    "        #Adding stock name as a new column to every data rows for identification.\n",
    "        summary_data_values.insert(0,stock_list[x])       \n",
    "        \n",
    "        print(z,\"summary_data_values\",\"--->>>\",summary_data_values)    \n",
    "        \n",
    "        #Creating base data frame to hold data for every stock\n",
    "        print('*****Columns******',cols,'^^^^DATA^^^^^',[summary_data_values])\n",
    "        share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "        \n",
    "        #Removing duplicate rows to avoid discrepency\n",
    "        share_summary = share_summary.loc[:,~share_summary.columns.duplicated()]\n",
    "        \n",
    "        #Creating final Data frame one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            #share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "            \n",
    "            all_share_summary = pd.DataFrame(columns= [share_summary])\n",
    "        print (\"Inside x loop\",x)\n",
    "            \n",
    "        #Adding individual stock data values through every iteration    \n",
    "        print(\"Final Datatypes\",\"<<<<<<<<->>>>>>>>\",all_share_summary.dtypes)\n",
    "        all_share_summary = all_share_summary._append(share_summary,ignore_index=True)\n",
    "        \n",
    "        #del(stock_detail_header,stock_detail_value,share_summary)\n",
    "        summary_data_values.clear()\n",
    "\n",
    "        #Stock Evalutation Ratings details-- END              \n",
    "        \n",
    "        #Quarterly earnings header objects-- START\n",
    "            \n",
    "        stock_detail_quarterly_headers = soup.find('table', class_ = \"table table-condensed tableDetails\", id = \"formattedSalesAndEarningTable\")\n",
    "        #Filtering table header content from soup objects - stock_detail_quarterly_headers\n",
    "        quarterly_objects = stock_detail_quarterly_headers.find_all('th')\n",
    "\n",
    "        #Iterating quarterly earnings headers by element to add into list for further processing\n",
    "        #Not iterating all rows because last rows is NULL\n",
    "        stock_quarterly_earnings_headers = [ title.text.strip() for title in quarterly_objects ]\n",
    "        stock_quarterly_earnings_headers.insert(0,\"Stock Name\")\n",
    "        #Removing last empty values in list on every iteration\n",
    "        stock_quarterly_earnings_headers.pop()\n",
    "        \n",
    "        \n",
    "        print(\"Final Quarterly Earnings Headers\",\"<<<<<>>>>>>\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        print(format(stock_list[x]),\"StockDetailHeader>>>\" ,stock_detail_header)\n",
    "        #print(format(lst[x]),\"QuarterlyEPSHeaders>>>\" , stock_detail_quarterly_headers)\n",
    "        print(stock_detail_quarterly_headers.find_all('th'))\n",
    "        \n",
    "        #Filtering data contents for Quarterly earnings\n",
    "        quarterly_objects_data = stock_detail_quarterly_headers.find_all('tr')\n",
    "        \n",
    "        #Creating final Data frame for quarterly earnings one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            #quarterly_earnings.rename(columns= {'Stock Name': 'stock_name', 'Date(Transcript )': 'date' , 'EPS' : 'eps', \\\n",
    "            #                                    '%Chg': 'eps_chg_pct', 'Sales(Cr)' : 'sales_in_cr', '%Chg': 'sales_chg_pct'},inplace= True)\n",
    "            print(\"Columns\",quarterly_earnings.columns)\n",
    "            \n",
    "            quarterly_earnings_all_stocks = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            \n",
    "        print(\"earnings dataframe\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        #Iterating individual quarterly earnings table row by element to add into list for further processing\n",
    "        quarterly_earnings_lst = []\n",
    "        for rows in quarterly_objects_data:\n",
    "            row_data = rows.find_all('td')\n",
    "            ind_quarterly_earnings_rows = [ q_data.text.strip() for q_data in row_data]\n",
    "            #Adding Stock name to quarterly earnings rows manually\n",
    "            ind_quarterly_earnings_rows.insert(0,stock_list[x])\n",
    "            #Removing last empty values in list on every iteration\n",
    "            ind_quarterly_earnings_rows.pop()\n",
    "            \n",
    "            #Adding iterated quarterly earnings data to list for a stock on their respective iteration of different quarters\n",
    "            quarterly_earnings_lst.append(ind_quarterly_earnings_rows)\n",
    "            \n",
    "            print(\"ind_quarterly_earnings_rows_Final Quarterly Earnings Headers rows\",\"<<<<<>>>>>>\",ind_quarterly_earnings_rows)\n",
    "        quarterly_earnings_lst.pop(0)\n",
    "        print(\"Final List\",\">><><><><><><><><>\",quarterly_earnings_lst)\n",
    "        \n",
    "        #Checking if all data values were empty for a respective stock in Marketsmith by \n",
    "        #moving list into set to avoid duplicate values and see if it matches '' empty value\n",
    "        if (len(quarterly_earnings_lst) == 1):\n",
    "            print(\"########Stock Not PresentSummary Set values#########\", quarterly_earnings_lst)\n",
    "            continue\n",
    "        \n",
    "        #Appending quarterly earnings rows stock specifically to dataframe \n",
    "        quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers, data = quarterly_earnings_lst)\n",
    "        quarterly_earnings_all_stocks = quarterly_earnings_all_stocks._append(quarterly_earnings, ignore_index=True)\n",
    "         \n",
    "    \n",
    "        print(\"QuarterlyEarnings Dataframe:\",quarterly_earnings)\n",
    "        \n",
    "        #Quarterly earnings header objects-- END\n",
    "\n",
    "        #Deleting objects cache to contents to store data in next iteration\n",
    "        soup.decompose()\n",
    "        \n",
    "        #Closing the driver    \n",
    "        driver.quit()\n",
    "        print(\"Next Iteration\")\n",
    "\n",
    "    #Data cleaning - Dropping unncessary columns\n",
    "    all_share_summary.drop(list(all_share_summary)[0:23], axis=1,inplace = True)\n",
    "    \n",
    "    #Renaming column name for SQL table processing\n",
    "    \n",
    "    all_share_summary.rename(columns = {'Stock Name' : 'stock_name', 'Market Capitalization' : 'market_capitalization', 'Sales' : 'sales', \\\n",
    "        'Shares in Float' : 'shares_in_float', 'No of Funds' : 'no_of_funds', 'Shares held by Funds' : 'shares_held_by_funds', 'Yield' : 'yield', \\\n",
    "        'Book Value' : 'book_value', 'U/D Vol Ratio' : 'u/d_vol_ratio', 'LTDebt/Equity' : 'ltdebt_equity', 'Alpha' : 'alpha', 'Beta' : 'beta', \\\n",
    "        'Master Score' : 'master_score', 'EPS Rating' : 'eps_rating', 'Price Strength' : 'price_strength', 'Acc/Dis Rating' : 'buyers_demand', \\\n",
    "        'Group Rank' : 'group_rank_out_of_197', 'EPS Growth Rate' : 'eps_growth_rate', 'Earnings Stability' : 'earnings_stability', 'P/E Ratio' : 'pe_ratio', \\\n",
    "        '5-Year P/E Range' : '5years_pe_range', 'Return on Equity' : 'return_on_equity', 'Cash Flow (INR)': 'cash_flow'},\n",
    "        inplace = True)\n",
    "    \n",
    "    \n",
    "    #Slicing EPS % Chg and Sales % Chg column as it is having same name so we have issue on processing it individually\n",
    "    #To overcome that we have renamed that to map EPS & Sales % change meaningfully \n",
    "    eps_pct = quarterly_earnings_all_stocks.iloc[:,3]\n",
    "    eps_pct.columns = ['eps_change_pct']\n",
    "    print(\"Sliced w dataframe:\",eps_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",eps_pct)\n",
    "    \n",
    "    sales_pct = quarterly_earnings_all_stocks.iloc[:,5]\n",
    "    sales_pct.columns = ['sales_change_pct']\n",
    "    print(\"Sliced w dataframe:\",sales_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",sales_pct)\n",
    "    \n",
    "    #Dropping existing %Change column we will add later below with appropriate\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.drop(columns = ['%Chg'])\n",
    "       \n",
    "    #Adding back the columns for EPS%Change and Sales%Change with right column names    \n",
    "    quarterly_earnings_all_stocks['EPS_Change_%'] = eps_pct\n",
    "    quarterly_earnings_all_stocks['SALES_Change_%'] = sales_pct\n",
    "    \n",
    "    \n",
    "    #Reindexing dataframe in appropriate order\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.reindex(['Stock Name','Date(Transcript )',\\\n",
    "                                    'EPS','EPS_Change_%','Sales(Cr)','SALES_Change_%'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Renaming the column names appropriately in final dataframe before inserting into SQL\n",
    "    quarterly_earnings_all_stocks.rename(columns={'Stock Name':'stock_name', 'Date(Transcript )': 'quarter', 'EPS':'eps', 'EPS_Change_%':'eps_pct_chg',\\\n",
    "                                                  'Sales(Cr)':'sales_in_cr', 'SALES_Change_%': 'sales_pct_chg'}, inplace= True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Final EPS DF columns\",\"##########\",quarterly_earnings_all_stocks.columns)\n",
    "    print(\"Final EPS Dataframe\",\"##########\",quarterly_earnings_all_stocks)\n",
    "        \n",
    "    #Removing INR string (text cleansing) from few columns to fit into perfect standard for data manipulation\n",
    "    all_share_summary.market_capitalization = all_share_summary.market_capitalization.str.replace('INR ','')\n",
    "    all_share_summary.sales = all_share_summary.sales.str.replace('INR ','')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace(' of 197','')\n",
    "    \n",
    "    \n",
    "    #Changing datatypes for the columns to their appropriate type for further processing\n",
    "    all_share_summary.master_score = all_share_summary.master_score.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.eps_rating = all_share_summary.eps_rating.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.price_strength = all_share_summary.price_strength.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.earnings_stability = all_share_summary.earnings_stability.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.pe_ratio = all_share_summary.pe_ratio.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace('N/A','0').astype('Int32')\n",
    "\n",
    "    \n",
    "    #quarterly_earnings_all_stocks.eps = quarterly_earnings_all_stocks.eps.str.replace('','0').astype('float64')\n",
    "    #quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace('','0').astype('float64')\n",
    "    #quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace(',','').astype('float64')\n",
    "    \n",
    "    \n",
    "    #Inserting stock data into SQL database using sqlachemy\n",
    "    \n",
    "    #Defining table name on MSSQL server to locate the data\n",
    "    stock_eval_table_name = \"market_smith_stock_eval_test\"\n",
    "    all_stocks_quarterly_earnings = \"all_stocks_quarterly_earnings_test\"\n",
    "    stock_institutional_ownership_data = \"market_smith_stock_institutional_data_test\"\n",
    "    sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "\n",
    "    db_conn= sql_engine.connect()\n",
    "\n",
    "    #DB Actions to load data from Pandas Dataframe to MSSQL\n",
    "    try:\n",
    "        all_share_summary.to_sql(stock_eval_table_name, db_conn, if_exists= 'append',index= False)\n",
    "        quarterly_earnings_all_stocks.to_sql(all_stocks_quarterly_earnings, db_conn, if_exists= 'append',index= False)\n",
    "        all_stocks_institutional_ownership_pivoted.to_sql(stock_institutional_ownership_data,db_conn, if_exists= 'append',index = False)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    else:\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(stock_eval_table_name))\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(all_stocks_quarterly_earnings))\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(stock_institutional_ownership_data))\n",
    "    finally:\n",
    "        db_conn.close()\n",
    "    \n",
    "    return all_share_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Stock_List: ['ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BPCL', 'BHARTIARTL', 'BRITANNIA', 'CIPLA', 'COALINDIA', 'DIVISLAB', 'DRREDDY', 'EICHERMOT', 'GRASIM', 'HCLTECH', 'HDFCBANK', 'HDFCLIFE', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR', 'ICICIBANK', 'ITC', 'INDUSINDBK', 'INFY', 'JSWSTEEL', 'KOTAKBANK', 'LTIM', 'LT', 'M&M', 'MARUTI', 'NTPC', 'NESTLEIND', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBILIFE', 'SHRIRAMFIN', 'SBIN', 'SUNPHARMA', 'TCS', 'TATACONSUM', 'TATAMOTORS', 'TATASTEEL', 'TECHM', 'TITAN', 'ULTRACEMCO', 'WIPRO']\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid object name 'market_smith_stock_eval_test'. (208) (SQLExecDirectW)\")\n[SQL: select top 1 [stock_name] From market_smith_stock_eval_test order by stock_name desc]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('42S02', \"[42S02] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid object name 'market_smith_stock_eval_test'. (208) (SQLExecDirectW)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m         sql_engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmssql+pyodbc://\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESKTOP-EQ55Q8H\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNSEBhavcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?trusted_connection=yes&driver=SQL+Server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m         db_conn\u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m---> 27\u001b[0m         top_stock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pd\u001b[38;5;241m.\u001b[39mread_sql_query(con \u001b[38;5;241m=\u001b[39m db_conn ,sql\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect top 1 [stock_name] From market_smith_stock_eval_test order by stock_name desc\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     28\u001b[0m         db_conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#Calling webscraping function\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:469\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    466\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    470\u001b[0m         sql,\n\u001b[0;32m    471\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    472\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    473\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[0;32m    474\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    475\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    476\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    477\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    478\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   1682\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1683\u001b[0m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1691\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;124;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1736\u001b[0m \n\u001b[0;32m   1737\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1738\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[0;32m   1739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1562\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1560\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexec_driver_sql(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1686\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a SQL statement construct and returns a\u001b[39;00m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;124;03m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \n\u001b[0;32m   1682\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m args_10style, kwargs_10style \u001b[38;5;241m=\u001b[39m _distill_params_20(parameters)\n\u001b[1;32m-> 1686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_driver_sql(\n\u001b[0;32m   1687\u001b[0m     statement,\n\u001b[0;32m   1688\u001b[0m     args_10style,\n\u001b[0;32m   1689\u001b[0m     kwargs_10style,\n\u001b[0;32m   1690\u001b[0m     execution_options,\n\u001b[0;32m   1691\u001b[0m     future\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1692\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         (\n\u001b[0;32m   1586\u001b[0m             statement,\n\u001b[0;32m   1587\u001b[0m             distilled_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[0;32m   1592\u001b[0m         )\n\u001b[0;32m   1594\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1595\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[0;32m   1596\u001b[0m     dialect,\n\u001b[0;32m   1597\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_statement,\n\u001b[0;32m   1598\u001b[0m     statement,\n\u001b[0;32m   1599\u001b[0m     distilled_parameters,\n\u001b[0;32m   1600\u001b[0m     execution_options,\n\u001b[0;32m   1601\u001b[0m     statement,\n\u001b[0;32m   1602\u001b[0m     distilled_parameters,\n\u001b[0;32m   1603\u001b[0m )\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2043\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m     )\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2047\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid object name 'market_smith_stock_eval_test'. (208) (SQLExecDirectW)\")\n[SQL: select top 1 [stock_name] From market_smith_stock_eval_test order by stock_name desc]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reading CSV file to fetch all listed Stocks from NSE website\n",
    "\n",
    "all_equity_lst = pd.read_csv(\"./ind_nifty50list.csv\")\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ind_stock in all_equity_lst['SYMBOL']:\n",
    "    stock_list.append(ind_stock)\n",
    "\n",
    "print(\"Inside Stock_List:\",stock_list)\n",
    "\n",
    "sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "table_trun_conn = sql_engine.connect()\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS market_smith_stock_eval_test\")\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS all_stocks_quarterly_earnings_test\")\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS market_smith_stock_institutional_data_test\")\n",
    "table_trun_conn.close()\n",
    "\n",
    "#Below code part is used to iterate every set of 10 stocks \n",
    "counter = 0\n",
    "top_stock = ''\n",
    "while (counter <= len(stock_list)):\n",
    "    time.sleep(4)\n",
    "    if(counter!=0):\n",
    "        sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "        db_conn= sql_engine.connect()\n",
    "        top_stock = str(pd.read_sql_query(con = db_conn ,sql='select top 1 [stock_name] From market_smith_stock_eval_test order by stock_name desc'))\n",
    "        db_conn.close()\n",
    "    \n",
    "#Calling webscraping function\n",
    "    if(stock_list[counter] != top_stock):\n",
    "        marketsmith_scrape(stock_list[counter:10+ counter])\n",
    "        counter = counter + 10\n",
    "        print('Next Iteration on WHILE LOOP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading CSV file to fetch all listed NSE Stocks from local folder\n",
    "all_equity_lst = pd.read_csv(\"./NSE_EQUITY_List.csv\")\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ind_stock in all_equity_lst['SYMBOL']:\n",
    "    stock_list.append(ind_stock)\n",
    "\n",
    "print(\"Inside Stock_List:\",stock_list)\n",
    "\n",
    "#Inserting stock data into SQL database using sqlachemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "\n",
    "db_conn= sql_engine.connect()\n",
    "\n",
    "sql_res = pd.read_sql_query(con = db_conn ,sql='select top 1 [stock_name] From market_smith_stock_eval order by stock_name desc')\n",
    "\n",
    "print(\"Last Stock Data in Table\",sql_res)\n",
    "\n",
    "db_conn.close()\n",
    "\n",
    "print(\"Index of Result\",stock_list[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
