{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the StringIO module.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import the requests library \n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Inserting stock data into SQL database using sqlachemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Defining headers with User agent to establish requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
    "'X-Requested-With': 'XMLHttpRequest'\n",
    "}\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lst = ['SBIN','TCS','HCLTECH','ROSSARI','PIDILITIND']\n",
    "\n",
    "#Function to scrape Marketsmith stock fundamental data\n",
    "def marketsmith_scrape(stock_list):\n",
    "    for x in tqdm(range(0,len(stock_list))):\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "\n",
    "        #Firefox browser webdriver\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "\n",
    "\n",
    "        #Google chrome webdriver\n",
    "        #options = webdriver.ChromeOptions()\n",
    "        #driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        #Base Url to fetch stock fundamental data through request\n",
    "\n",
    "\n",
    "        url = \"https://marketsmithindia.com/mstool/eval/{}/evaluation.jsp#/\".format(stock_list[x])\n",
    "        print(url)\n",
    "    \n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "\n",
    "        #Populating stock ratings data for individual stocks from Marketsmith evaluation pages\n",
    "        if x==0:\n",
    "            stock_detail_header = soup.find_all('div', class_ = \"details\")\n",
    "        \n",
    "        #Quarterly earnings header objects\n",
    "            \n",
    "        stock_detail_quarterly_headers = soup.find('table', class_ = \"table table-condensed tableDetails\", id = \"formattedSalesAndEarningTable\")\n",
    "        #Filtering table header content from soup objects - stock_detail_quarterly_headers\n",
    "        quarterly_objects = stock_detail_quarterly_headers.find_all('th')\n",
    "\n",
    "        #Iterating quarterly earnings headers by element to add into list for further processing\n",
    "        #Not iterating all rows because last rows is NULL\n",
    "        stock_quarterly_earnings_headers = [ title.text.strip() for title in quarterly_objects ]\n",
    "        stock_quarterly_earnings_headers.insert(0,\"Stock Name\")\n",
    "        #Removing last empty values in list on every iteration\n",
    "        stock_quarterly_earnings_headers.pop()\n",
    "        \n",
    "        \n",
    "        print(\"Final Quarterly Earnings Headers\",\"<<<<<>>>>>>\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        print(format(stock_list[x]),\"StockDetailHeader>>>\" ,stock_detail_header)\n",
    "        #print(format(lst[x]),\"QuarterlyEPSHeaders>>>\" , stock_detail_quarterly_headers)\n",
    "        print(stock_detail_quarterly_headers.find_all('th'))\n",
    "        \n",
    "        #Filtering data contents for Quarterly earnings\n",
    "        quarterly_objects_data = stock_detail_quarterly_headers.find_all('tr')\n",
    "        \n",
    "        #Creating final Data frame for quarterly earnings one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            #quarterly_earnings.rename(columns= {'Stock Name': 'stock_name', 'Date(Transcript )': 'date' , 'EPS' : 'eps', \\\n",
    "            #                                    '%Chg': 'eps_chg_pct', 'Sales(Cr)' : 'sales_in_cr', '%Chg': 'sales_chg_pct'},inplace= True)\n",
    "            print(\"Columns\",quarterly_earnings.columns)\n",
    "            \n",
    "            quarterly_earnings_all_stocks = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            \n",
    "        print(\"earnings dataframe\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        #Iterating individual quarterly earnings table row by element to add into list for further processing\n",
    "        quarterly_earnings_lst = []\n",
    "        for rows in quarterly_objects_data:\n",
    "            row_data = rows.find_all('td')\n",
    "            ind_quarterly_earnings_rows = [ q_data.text.strip() for q_data in row_data]\n",
    "            #Adding Stock name to quarterly earnings rows manually\n",
    "            ind_quarterly_earnings_rows.insert(0,stock_list[x])\n",
    "            #Removing last empty values in list on every iteration\n",
    "            ind_quarterly_earnings_rows.pop()\n",
    "            \n",
    "            #Adding iterated quarterly earnings data to list for a stock on their respective iteration of different quarters\n",
    "            quarterly_earnings_lst.append(ind_quarterly_earnings_rows)\n",
    "            \n",
    "            print(\"ind_quarterly_earnings_rows_Final Quarterly Earnings Headers rows\",\"<<<<<>>>>>>\",ind_quarterly_earnings_rows)\n",
    "        quarterly_earnings_lst.pop(0)\n",
    "        print(\"Final List\",\">><><><><><><><><>\",quarterly_earnings_lst)\n",
    "        \n",
    "        #Appending quarterly earnings rows stock specifically to dataframe \n",
    "        quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers, data = quarterly_earnings_lst)\n",
    "        quarterly_earnings_all_stocks = quarterly_earnings_all_stocks._append(quarterly_earnings, ignore_index=True)\n",
    "         \n",
    "    \n",
    "        \n",
    "        \n",
    "        print(\"QuarterlyEarnings Dataframe:\",quarterly_earnings)\n",
    "        \n",
    "        stock_detail_value = soup.find_all('div', class_ = \"value\")\n",
    "        print(format(stock_list[x]),\">>>\",stock_detail_value)\n",
    "        \n",
    "        cols = []\n",
    "        \n",
    "        \n",
    "        #Generating columns through iteration\n",
    "        \n",
    "        for y in range(0,len(stock_detail_header)):\n",
    "            cols.append(stock_detail_header[y].get_text().strip())\n",
    "            \n",
    "        #Creating a new column for stock wise segregation\n",
    "        cols.insert(0,\"Stock Name\")\n",
    "        \n",
    "        print(y,\"columns\",\"--->>>\",cols)\n",
    "        \n",
    "        \n",
    "        #share_summary = pd.DataFrame(columns= cols)\n",
    "        \n",
    "        \n",
    "        #Feeding an empty Dataframe with its respective column values through iterating summary_data list\n",
    "        #Creating an empty Dataframe to feed the column names through iterating summary_cols list\n",
    "\n",
    "        summary_data_values = []\n",
    "        \n",
    "\n",
    "        #Generating columns data through iteration\n",
    "        for z in range(0,len(stock_detail_value)):\n",
    "            print(stock_detail_value[z].get_text().strip())\n",
    "            summary_data_values.append(stock_detail_value[z].get_text().strip())\n",
    "        \n",
    "        #Adding stock name as a new column to every data rows for identification.\n",
    "        summary_data_values.insert(0,stock_list[x])       \n",
    "        \n",
    "        print(z,\"summary_data_values\",\"--->>>\",summary_data_values)    \n",
    "        \n",
    "        #Creating base data frame to hold data for every stock\n",
    "        share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "        \n",
    "        #Removing duplicate rows to avoid discrepency\n",
    "        share_summary = share_summary.loc[:,~share_summary.columns.duplicated()]\n",
    "        \n",
    "        #Creating final Data frame one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            #share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "            \n",
    "            all_share_summary = pd.DataFrame(columns= [share_summary])\n",
    "        print (\"Inside x loop\",x)\n",
    "            \n",
    "        #Adding individual stock data values through every iteration    \n",
    "        print(\"Final Datatypes\",\"<<<<<<<<->>>>>>>>\",all_share_summary.dtypes)\n",
    "        all_share_summary = all_share_summary._append(share_summary,ignore_index=True)\n",
    "        \n",
    "        #del(stock_detail_header,stock_detail_value,share_summary)\n",
    "        summary_data_values.clear()\n",
    "\n",
    "        \n",
    "\n",
    "        #Deleting objects cache to contents to store data in next iteration\n",
    "        soup.decompose()\n",
    "        \n",
    "        #Closing the driver    \n",
    "        driver.quit()\n",
    "        \n",
    "        print(\"Next Iteration\")\n",
    "\n",
    "    #Data cleaning - Dropping unncessary columns\n",
    "    all_share_summary.drop(list(all_share_summary)[0:23], axis=1,inplace = True)\n",
    "    \n",
    "    #Renaming column name for SQL table processing\n",
    "    \n",
    "    all_share_summary.rename(columns = {'Stock Name' : 'stock_name', 'Market Capitalization' : 'market_capitalization', 'Sales' : 'sales', \\\n",
    "        'Shares in Float' : 'shares_in_float', 'No of Funds' : 'no_of_funds', 'Shares held by Funds' : 'shares_held_by_funds', 'Yield' : 'yield', \\\n",
    "        'Book Value' : 'book_value', 'U/D Vol Ratio' : 'u/d_vol_ratio', 'LTDebt/Equity' : 'ltdebt_equity', 'Alpha' : 'alpha', 'Beta' : 'beta', \\\n",
    "        'Master Score' : 'master_score', 'EPS Rating' : 'eps_rating', 'Price Strength' : 'price_strength', 'Acc/Dis Rating' : 'buyers_demand', \\\n",
    "        'Group Rank' : 'group_rank_out_of_197', 'EPS Growth Rate' : 'eps_growth_rate', 'Earnings Stability' : 'earnings_stability', 'P/E Ratio' : 'pe_ratio', \\\n",
    "        '5-Year P/E Range' : '5years_pe_range', 'Return on Equity' : 'return_on_equity', 'Cash Flow (INR)': 'cash_flow'},\n",
    "        inplace = True)\n",
    "    \n",
    "    \n",
    "    #Slicing EPS % Chg and Sales % Chg column as it is having same name so we have issue on processing it individually\n",
    "    #To overcome that we have renamed that to map EPS & Sales % change meaningfully \n",
    "    eps_pct = quarterly_earnings_all_stocks.iloc[:,3]\n",
    "    eps_pct.columns = ['eps_change_pct']\n",
    "    print(\"Sliced w dataframe:\",eps_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",eps_pct)\n",
    "    \n",
    "    sales_pct = quarterly_earnings_all_stocks.iloc[:,5]\n",
    "    sales_pct.columns = ['sales_change_pct']\n",
    "    print(\"Sliced w dataframe:\",sales_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",sales_pct)\n",
    "    \n",
    "    #Dropping existing %Change column we will add later below with appropriate\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.drop(columns = ['%Chg'])\n",
    "       \n",
    "    #Adding back the columns for EPS%Change and Sales%Change with right column names    \n",
    "    quarterly_earnings_all_stocks['EPS_Change_%'] = eps_pct\n",
    "    quarterly_earnings_all_stocks['SALES_Change_%'] = sales_pct\n",
    "    \n",
    "    \n",
    "    #Reindexing dataframe in appropriate order\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.reindex(['Stock Name','Date(Transcript )',\\\n",
    "                                    'EPS','EPS_Change_%','Sales(Cr)','SALES_Change_%'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Renaming the column names appropriately in final dataframe before inserting into SQL\n",
    "    quarterly_earnings_all_stocks.rename(columns={'Stock Name':'stock_name', 'Date(Transcript )': 'quarter', 'EPS':'eps', 'EPS_Change_%':'eps_pct_chg',\\\n",
    "                                                  'Sales(Cr)':'sales_in_cr', 'SALES_Change_%': 'sales_pct_chg'}, inplace= True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Final EPS DF columns\",\"##########\",quarterly_earnings_all_stocks.columns)\n",
    "    print(\"Final EPS Dataframe\",\"##########\",quarterly_earnings_all_stocks)\n",
    "        \n",
    "    #Removing INR string (text cleansing) from few columns to fit into perfect standard for data manipulation\n",
    "    all_share_summary.market_capitalization = all_share_summary.market_capitalization.str.replace('INR ','')\n",
    "    all_share_summary.sales = all_share_summary.sales.str.replace('INR ','')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace(' of 197','')\n",
    "    \n",
    "    \n",
    "    #Changing datatypes for the columns to their appropriate type for further processing\n",
    "    all_share_summary.master_score = all_share_summary.master_score.str.replace(['N/A',''],'0').astype('Int32')\n",
    "    all_share_summary.eps_rating = all_share_summary.eps_rating.str.replace(['N/A',''],'0').astype('Int32')\n",
    "    all_share_summary.price_strength = all_share_summary.price_strength.str.replace(['N/A',''],'0').astype('Int32')\n",
    "    all_share_summary.earnings_stability = all_share_summary.earnings_stability.str.replace(['N/A',''],'0').astype('Int32')\n",
    "    all_share_summary.pe_ratio = all_share_summary.pe_ratio.str.replace(['N/A',''],'0').astype('Int32')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace(['N/A',''],'0').astype('Int32')\n",
    "\n",
    "    \n",
    "    quarterly_earnings_all_stocks.eps = quarterly_earnings_all_stocks.eps.str.replace(['N/A',''],'0').astype('float64')\n",
    "    quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace(['N/A',''],'0').astype('float64')\n",
    "    #quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace(',','').astype('float64')\n",
    "    \n",
    "    \n",
    "    #Inserting stock data into SQL database using sqlachemy\n",
    "    \n",
    "    #Defining table name on MSSQL server to locate the data\n",
    "    stock_eval_table_name = \"market_smith_stock_eval\"\n",
    "    all_stocks_quarterly_earnings = \"all_stocks_quarterly_earnings\"\n",
    "    sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "\n",
    "    db_conn= sql_engine.connect()\n",
    "\n",
    "    #DB Actions to load data from Pandas Dataframe to MSSQL\n",
    "    try:\n",
    "        all_share_summary.to_sql(stock_eval_table_name, db_conn, if_exists= 'replace',index= False)\n",
    "        quarterly_earnings_all_stocks.to_sql(all_stocks_quarterly_earnings, db_conn, if_exists= 'replace',index= False)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    else:\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(stock_eval_table_name))\n",
    "        #print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(all_stocks_quarterly_earnings))\n",
    "    finally:\n",
    "        db_conn.close()\n",
    "    \n",
    "    return all_share_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_equity_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Reading CSV file to fetch all listed NSE Stocks from local folder\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#all_equity_lst = pd.read_csv(\"./NSE_EQUITY_List.csv\")\u001b[39;00m\n\u001b[0;32m     11\u001b[0m stock_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind_stock \u001b[38;5;129;01min\u001b[39;00m all_equity_lst[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYMBOL\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     14\u001b[0m     stock_list\u001b[38;5;241m.\u001b[39mappend(ind_stock)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInside Stock_List:\u001b[39m\u001b[38;5;124m\"\u001b[39m,stock_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_equity_lst' is not defined"
     ]
    }
   ],
   "source": [
    "#lst = ['M&M']\n",
    "'''\n",
    "lst =['ADANIENT','ADANIPORTS','APOLLOHOSP','ASIANPAINT','AXISBANK','BAJAJ-AUTO','BAJAJFINSV','BAJFINANCE','BHARTIARTL','BPCL','BRITANNIA','CIPLA','COALINDIA',\n",
    "'DIVISLAB','DRREDDY','EICHERMOT','GRASIM','HCLTECH','HDFCBANK','HDFCLIFE','HEROMOTOCO','HINDALCO','HINDUNILVR','ICICIBANK','INDUSINDBK','INFY','ITC','JSWSTEEL',\n",
    "'KOTAKBANK','LT','LTIM','M&M','MARUTI','NESTLEIND','NTPC','ONGC','POWERGRID','RELIANCE','SBILIFE','SBIN','SHRIRAMFIN','SUNPHARMA','TATACONSUM',\n",
    "'TATAMOTORS','TATASTEEL','TCS','TECHM','TITAN','ULTRACEMCO','WIPRO']\n",
    "'''\n",
    "#Reading CSV file to fetch all listed NSE Stocks from local folder\n",
    "all_equity_lst = pd.read_csv(\"./NSE_EQUITY_List.csv\")\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ind_stock in all_equity_lst['SYMBOL']:\n",
    "    stock_list.append(ind_stock)\n",
    "\n",
    "print(\"Inside Stock_List:\",stock_list)\n",
    "\n",
    "#Calling webscraping function\n",
    "marketsmith_scrape(stock_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
