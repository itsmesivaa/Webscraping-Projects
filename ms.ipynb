{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MarketSmith WebScraping Stock Evaluation Rating Details, Quarterly Earnings Details for Every Stocks using Selenium and Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the StringIO module.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import the requests library \n",
    "import requests\n",
    "\n",
    "# Importing the StringIO module.\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Inserting stock data into SQL database using sqlachemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Defining headers with User agent to establish requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
    "'X-Requested-With': 'XMLHttpRequest'\n",
    "}\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function to scrape Marketsmith stock fundamental data\n",
    "def marketsmith_scrape(stock_list):\n",
    "    \n",
    "    for x in tqdm(range(0,len(stock_list))):\n",
    "        time.sleep(2)\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "\n",
    "        #Firefox browser webdriver\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "\n",
    "        #Google chrome webdriver\n",
    "        #options = webdriver.ChromeOptions()\n",
    "        #driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        #Base Url to fetch stock fundamental data through request\n",
    "        url = \"https://marketsmithindia.com/mstool/eval/{}/evaluation.jsp#/\".format(stock_list[x])\n",
    "        print(url)\n",
    "        driver.get(url)\n",
    "        #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "\n",
    "        #Populating stock ratings data for individual stocks from Marketsmith evaluation pages\n",
    "        #Populating stock ownership institution details for individual stocks from Marketsmith evaluation pages\n",
    "        if x==0:\n",
    "            stock_detail_header = soup.find_all('div', class_ = \"details\")\n",
    "            \n",
    "        \n",
    "        #Stock Ownership & Institution Details - START\n",
    "        stock_ownership_header = soup.find('table', \\\n",
    "                    class_ = \"table table-condensed tableDetails managementTablefont removeTableMargin\", \\\n",
    "                    id = \"chartTable\")\n",
    "        \n",
    "        ownership_header_object = stock_ownership_header.find_all('th')\n",
    "        #Iterating ownership headers by element to add into list for further processing\n",
    "        #Not iterating all rows because last rows is NULL\n",
    "        stock_ownership_institution_headers = [ head.text.strip() for head in ownership_header_object ]\n",
    "        stock_ownership_institution_headers.insert(0,\"Stock Name\")\n",
    "        print('Institution Details<<<<<<<<<<Final Stock Institution Headers',stock_ownership_institution_headers)\n",
    "        \n",
    "        #Filtering data contents for stock ownership details\n",
    "        stock_ownership_header_rows = stock_ownership_header.find_all('tr')\n",
    "        \n",
    "        #Creating final Data frame for quarterly earnings one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            df_temp_ownership = pd.DataFrame(columns= stock_ownership_institution_headers)\n",
    "            \n",
    "            print(\"DF OwnershipColumns\",df_temp_ownership.columns)\n",
    "            \n",
    "            all_stocks_institutional_ownership = pd.DataFrame(columns= df_temp_ownership)\n",
    "            \n",
    "        print(\"Institution Ownership Dataframe\",all_stocks_institutional_ownership)\n",
    "        \n",
    "        #Iterating individual quarterly earnings table row by element to add into list for further processing\n",
    "        stock_institution_data = []\n",
    "        for data in stock_ownership_header_rows:\n",
    "            owner_row_data = data.find_all('td')\n",
    "            institution_data = [ q_data.text.strip() for q_data in owner_row_data]\n",
    "            #Adding Stock name to institution rows manually\n",
    "            institution_data.insert(0,stock_list[x])\n",
    "            \n",
    "            #Adding iterated institution data to list for a stock on their respective iteration of different quarters\n",
    "            stock_institution_data.append(institution_data)\n",
    "            \n",
    "            print(\"Stock Institution Data\",\"<<<<<>>>>>>\",institution_data)\n",
    "        #Removing NULL data from the list            \n",
    "        stock_institution_data.pop(0)\n",
    "        print(\"Final List\",\">><><><><><><><><>\",stock_institution_data)\n",
    "        \n",
    "        #Appending institution details rows stock specifically to dataframe \n",
    "        df_temp_ownership = pd.DataFrame(columns= stock_ownership_institution_headers, data = stock_institution_data)\n",
    "        all_stocks_institutional_ownership = all_stocks_institutional_ownership._append(df_temp_ownership, ignore_index=True)\n",
    "        \n",
    "        print(\"******Before Institutional Data for each Stocks Dataframe:******\",all_stocks_institutional_ownership)\n",
    "        # melt the dataframe to create a single column for Quarter\n",
    "        all_stocks_institutional_ownership_melted = pd.melt(all_stocks_institutional_ownership, id_vars=['Stock Name', 'Owner Name'], \\\n",
    "                                                    var_name='Quarter', value_name='Percentage')\n",
    "\n",
    "        # pivot the dataframe to create separate columns for each Owner Name\n",
    "        all_stocks_institutional_ownership_pivoted = all_stocks_institutional_ownership_melted.pivot_table(index=['Stock Name', 'Quarter'], \\\n",
    "                                                    columns='Owner Name', values='Percentage', aggfunc='first').reset_index()\n",
    "        #Handling NAN values with zero\n",
    "        all_stocks_institutional_ownership_pivoted.fillna(0)\n",
    "        #Making Column name to Lowercase for further processing to meet standard\n",
    "        all_stocks_institutional_ownership_pivoted.columns.str.lower()\n",
    "        #Appropriate naming convention format for column names\n",
    "        all_stocks_institutional_ownership_pivoted.columns = all_stocks_institutional_ownership_pivoted.columns.str.\\\n",
    "                                                             replace(' ','', regex=True)\n",
    "        \n",
    "        print(\"******After Institutional Data for each Stocks Dataframe:******\", all_stocks_institutional_ownership_pivoted)\n",
    "        #Stock Ownership & Institution Details - END\n",
    "        \n",
    "        \n",
    "        #Stock Evalutation Ratings details-- START\n",
    "        cols = []        \n",
    "        #Generating columns through iteration for stock_detail_header\n",
    "        \n",
    "        for y in range(0,len(stock_detail_header)):\n",
    "            cols.append(stock_detail_header[y].get_text().strip())\n",
    "            \n",
    "        #Creating a new column for stock wise segregation\n",
    "        cols.insert(0,\"Stock Name\")\n",
    "        \n",
    "        print(y,\"columns\",\"--->>>\",cols)\n",
    "        \n",
    "        #Generating row values for the stock_detail_header header \n",
    "        stock_detail_value = soup.find_all('div', class_ = \"value\")\n",
    "        print(format(stock_list[x]),\"StockDetailValue>>>\",stock_detail_value) \n",
    "        \n",
    "\n",
    "        #Feeding an empty Dataframe with its respective column values through iterating summary_data list\n",
    "        #Creating an empty Dataframe to feed the column names through iterating summary_cols list\n",
    "\n",
    "        summary_data_values = []\n",
    "        \n",
    "\n",
    "        #Generating columns data through iteration\n",
    "        for z in range(0,len(stock_detail_value)):\n",
    "            print(stock_detail_value[z].get_text().strip())\n",
    "            summary_data_values.append(stock_detail_value[z].get_text().strip())\n",
    "        \n",
    "        #Checking if all data values were empty for a respective stock in Marketsmith by \n",
    "        #moving list into set to avoid duplicate values and see if it matches '' empty value\n",
    "        if ('' in (set(summary_data_values))):\n",
    "            print(\"########Stock Not PresentSummary Set values#########\", set(summary_data_values))\n",
    "            continue\n",
    "        \n",
    "        #Adding stock name as a new column to every data rows for identification.\n",
    "        summary_data_values.insert(0,stock_list[x])       \n",
    "        \n",
    "        print(z,\"summary_data_values\",\"--->>>\",summary_data_values)    \n",
    "        \n",
    "        #Creating base data frame to hold data for every stock\n",
    "        print('*****Columns******',cols,'^^^^DATA^^^^^',[summary_data_values])\n",
    "        share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "        \n",
    "        #Removing duplicate rows to avoid discrepency\n",
    "        share_summary = share_summary.loc[:,~share_summary.columns.duplicated()]\n",
    "        \n",
    "        #Creating final Data frame one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            #share_summary = pd.DataFrame(columns= cols,data = [summary_data_values])\n",
    "            \n",
    "            all_share_summary = pd.DataFrame(columns= [share_summary])\n",
    "        print (\"Inside x loop\",x)\n",
    "            \n",
    "        #Adding individual stock data values through every iteration    \n",
    "        print(\"Final Datatypes\",\"<<<<<<<<->>>>>>>>\",all_share_summary.dtypes)\n",
    "        all_share_summary = all_share_summary._append(share_summary,ignore_index=True)\n",
    "        \n",
    "        #del(stock_detail_header,stock_detail_value,share_summary)\n",
    "        summary_data_values.clear()\n",
    "\n",
    "        #Stock Evalutation Ratings details-- END              \n",
    "        \n",
    "        #Quarterly earnings header objects-- START\n",
    "            \n",
    "        stock_detail_quarterly_headers = soup.find('table', class_ = \"table table-condensed tableDetails\", id = \"formattedSalesAndEarningTable\")\n",
    "        #Filtering table header content from soup objects - stock_detail_quarterly_headers\n",
    "        quarterly_objects = stock_detail_quarterly_headers.find_all('th')\n",
    "\n",
    "        #Iterating quarterly earnings headers by element to add into list for further processing\n",
    "        #Not iterating all rows because last rows is NULL\n",
    "        stock_quarterly_earnings_headers = [ title.text.strip() for title in quarterly_objects ]\n",
    "        stock_quarterly_earnings_headers.insert(0,\"Stock Name\")\n",
    "        #Removing last empty values in list on every iteration\n",
    "        stock_quarterly_earnings_headers.pop()\n",
    "        \n",
    "        \n",
    "        print(\"Final Quarterly Earnings Headers\",\"<<<<<>>>>>>\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        print(format(stock_list[x]),\"StockDetailHeader>>>\" ,stock_detail_header)\n",
    "        #print(format(lst[x]),\"QuarterlyEPSHeaders>>>\" , stock_detail_quarterly_headers)\n",
    "        print(stock_detail_quarterly_headers.find_all('th'))\n",
    "        \n",
    "        #Filtering data contents for Quarterly earnings\n",
    "        quarterly_objects_data = stock_detail_quarterly_headers.find_all('tr')\n",
    "        \n",
    "        #Creating final Data frame for quarterly earnings one time and from base dataframe structure\n",
    "        if x==0:\n",
    "            quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            #quarterly_earnings.rename(columns= {'Stock Name': 'stock_name', 'Date(Transcript )': 'date' , 'EPS' : 'eps', \\\n",
    "            #                                    '%Chg': 'eps_chg_pct', 'Sales(Cr)' : 'sales_in_cr', '%Chg': 'sales_chg_pct'},inplace= True)\n",
    "            print(\"Columns\",quarterly_earnings.columns)\n",
    "            \n",
    "            quarterly_earnings_all_stocks = pd.DataFrame(columns= stock_quarterly_earnings_headers)\n",
    "            \n",
    "        print(\"earnings dataframe\",stock_quarterly_earnings_headers)\n",
    "        \n",
    "        #Iterating individual quarterly earnings table row by element to add into list for further processing\n",
    "        quarterly_earnings_lst = []\n",
    "        for rows in quarterly_objects_data:\n",
    "            row_data = rows.find_all('td')\n",
    "            ind_quarterly_earnings_rows = [ q_data.text.strip() for q_data in row_data]\n",
    "            #Adding Stock name to quarterly earnings rows manually\n",
    "            ind_quarterly_earnings_rows.insert(0,stock_list[x])\n",
    "            #Removing last empty values in list on every iteration\n",
    "            ind_quarterly_earnings_rows.pop()\n",
    "            \n",
    "            #Adding iterated quarterly earnings data to list for a stock on their respective iteration of different quarters\n",
    "            quarterly_earnings_lst.append(ind_quarterly_earnings_rows)\n",
    "            \n",
    "            print(\"ind_quarterly_earnings_rows_Final Quarterly Earnings Headers rows\",\"<<<<<>>>>>>\",ind_quarterly_earnings_rows)\n",
    "        quarterly_earnings_lst.pop(0)\n",
    "        print(\"Final List\",\">><><><><><><><><>\",quarterly_earnings_lst)\n",
    "        \n",
    "        #Checking if all data values were empty for a respective stock in Marketsmith by \n",
    "        #moving list into set to avoid duplicate values and see if it matches '' empty value\n",
    "        if (len(quarterly_earnings_lst) == 1):\n",
    "            print(\"########Stock Not PresentSummary Set values#########\", quarterly_earnings_lst)\n",
    "            continue\n",
    "        \n",
    "        #Appending quarterly earnings rows stock specifically to dataframe \n",
    "        quarterly_earnings = pd.DataFrame(columns= stock_quarterly_earnings_headers, data = quarterly_earnings_lst)\n",
    "        quarterly_earnings_all_stocks = quarterly_earnings_all_stocks._append(quarterly_earnings, ignore_index=True)\n",
    "         \n",
    "    \n",
    "        print(\"QuarterlyEarnings Dataframe:\",quarterly_earnings)\n",
    "        \n",
    "        #Quarterly earnings header objects-- END\n",
    "\n",
    "        #Deleting objects cache to contents to store data in next iteration\n",
    "        soup.decompose()\n",
    "        \n",
    "        #Closing the driver    \n",
    "        driver.quit()\n",
    "        print(\"Next Iteration\")\n",
    "\n",
    "    #Data cleaning - Dropping unncessary columns\n",
    "    all_share_summary.drop(list(all_share_summary)[0:23], axis=1,inplace = True)\n",
    "    \n",
    "    #Renaming column name for SQL table processing\n",
    "    \n",
    "    all_share_summary.rename(columns = {'Stock Name' : 'stock_name', 'Market Capitalization' : 'market_capitalization', 'Sales' : 'sales', \\\n",
    "        'Shares in Float' : 'shares_in_float', 'No of Funds' : 'no_of_funds', 'Shares held by Funds' : 'shares_held_by_funds', 'Yield' : 'yield', \\\n",
    "        'Book Value' : 'book_value', 'U/D Vol Ratio' : 'u/d_vol_ratio', 'LTDebt/Equity' : 'ltdebt_equity', 'Alpha' : 'alpha', 'Beta' : 'beta', \\\n",
    "        'Master Score' : 'master_score', 'EPS Rating' : 'eps_rating', 'Price Strength' : 'price_strength', 'Acc/Dis Rating' : 'buyers_demand', \\\n",
    "        'Group Rank' : 'group_rank_out_of_197', 'EPS Growth Rate' : 'eps_growth_rate', 'Earnings Stability' : 'earnings_stability', 'P/E Ratio' : 'pe_ratio', \\\n",
    "        '5-Year P/E Range' : '5years_pe_range', 'Return on Equity' : 'return_on_equity', 'Cash Flow (INR)': 'cash_flow'},\n",
    "        inplace = True)\n",
    "    \n",
    "    \n",
    "    #Slicing EPS % Chg and Sales % Chg column as it is having same name so we have issue on processing it individually\n",
    "    #To overcome that we have renamed that to map EPS & Sales % change meaningfully \n",
    "    eps_pct = quarterly_earnings_all_stocks.iloc[:,3]\n",
    "    eps_pct.columns = ['eps_change_pct']\n",
    "    print(\"Sliced w dataframe:\",eps_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",eps_pct)\n",
    "    \n",
    "    sales_pct = quarterly_earnings_all_stocks.iloc[:,5]\n",
    "    sales_pct.columns = ['sales_change_pct']\n",
    "    print(\"Sliced w dataframe:\",sales_pct.columns)\n",
    "    print(\"Sliced w dataframe:\",sales_pct)\n",
    "    \n",
    "    #Dropping existing %Change column we will add later below with appropriate\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.drop(columns = ['%Chg'])\n",
    "       \n",
    "    #Adding back the columns for EPS%Change and Sales%Change with right column names    \n",
    "    quarterly_earnings_all_stocks['EPS_Change_%'] = eps_pct\n",
    "    quarterly_earnings_all_stocks['SALES_Change_%'] = sales_pct\n",
    "    \n",
    "    \n",
    "    #Reindexing dataframe in appropriate order\n",
    "    quarterly_earnings_all_stocks = quarterly_earnings_all_stocks.reindex(['Stock Name','Date(Transcript )',\\\n",
    "                                    'EPS','EPS_Change_%','Sales(Cr)','SALES_Change_%'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Renaming the column names appropriately in final dataframe before inserting into SQL\n",
    "    quarterly_earnings_all_stocks.rename(columns={'Stock Name':'stock_name', 'Date(Transcript )': 'quarter', 'EPS':'eps', 'EPS_Change_%':'eps_pct_chg',\\\n",
    "                                                  'Sales(Cr)':'sales_in_cr', 'SALES_Change_%': 'sales_pct_chg'}, inplace= True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Final EPS DF columns\",\"##########\",quarterly_earnings_all_stocks.columns)\n",
    "    print(\"Final EPS Dataframe\",\"##########\",quarterly_earnings_all_stocks)\n",
    "        \n",
    "    #Removing INR string (text cleansing) from few columns to fit into perfect standard for data manipulation\n",
    "    all_share_summary.market_capitalization = all_share_summary.market_capitalization.str.replace('INR ','')\n",
    "    all_share_summary.sales = all_share_summary.sales.str.replace('INR ','')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace(' of 197','')\n",
    "    \n",
    "    \n",
    "    #Changing datatypes for the columns to their appropriate type for further processing\n",
    "    all_share_summary.master_score = all_share_summary.master_score.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.eps_rating = all_share_summary.eps_rating.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.price_strength = all_share_summary.price_strength.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.earnings_stability = all_share_summary.earnings_stability.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.pe_ratio = all_share_summary.pe_ratio.str.replace('N/A','0').astype('Int32')\n",
    "    all_share_summary.group_rank_out_of_197 = all_share_summary.group_rank_out_of_197.str.replace('N/A','0').astype('Int32')\n",
    "\n",
    "    \n",
    "    #quarterly_earnings_all_stocks.eps = quarterly_earnings_all_stocks.eps.str.replace('','0').astype('float64')\n",
    "    #quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace('','0').astype('float64')\n",
    "    #quarterly_earnings_all_stocks.sales_in_cr = quarterly_earnings_all_stocks.sales_in_cr.str.replace(',','').astype('float64')\n",
    "    \n",
    "    \n",
    "    #Inserting stock data into SQL database using sqlachemy\n",
    "    \n",
    "    #Defining table name on MSSQL server to locate the data\n",
    "    stock_eval_table_name = \"market_smith_stock_eval_test\"\n",
    "    all_stocks_quarterly_earnings = \"all_stocks_quarterly_earnings_test\"\n",
    "    stock_institutional_ownership_data = \"market_smith_stock_institutional_data_test\"\n",
    "    sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "\n",
    "    db_conn= sql_engine.connect()\n",
    "\n",
    "    #DB Actions to load data from Pandas Dataframe to MSSQL\n",
    "    try:\n",
    "        all_share_summary.to_sql(stock_eval_table_name, db_conn, if_exists= 'append',index= False)\n",
    "        quarterly_earnings_all_stocks.to_sql(all_stocks_quarterly_earnings, db_conn, if_exists= 'append',index= False)\n",
    "        all_stocks_institutional_ownership_pivoted.to_sql(stock_institutional_ownership_data,db_conn, if_exists= 'append',index = False)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    else:\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(stock_eval_table_name))\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(all_stocks_quarterly_earnings))\n",
    "        print('Marketsmith Stock Evalulation data successfully inserted into MS SQL table-{}'.format(stock_institutional_ownership_data))\n",
    "    finally:\n",
    "        db_conn.close()\n",
    "    \n",
    "    return all_share_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Stock_List: ['ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BPCL', 'BHARTIARTL', 'BRITANNIA', 'CIPLA', 'COALINDIA', 'DIVISLAB', 'DRREDDY', 'EICHERMOT', 'GRASIM', 'HCLTECH', 'HDFCBANK', 'HDFCLIFE', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR', 'ICICIBANK', 'ITC', 'INDUSINDBK', 'INFY', 'JSWSTEEL', 'KOTAKBANK', 'LTIM', 'LT', 'M&M', 'MARUTI', 'NTPC', 'NESTLEIND', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBILIFE', 'SHRIRAMFIN', 'SBIN', 'SUNPHARMA', 'TCS', 'TATACONSUM', 'TATAMOTORS', 'TATASTEEL', 'TECHM', 'TITAN', 'ULTRACEMCO', 'WIPRO']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reading CSV file to fetch all listed Stocks from NSE website\n",
    "\n",
    "all_equity_lst = pd.read_csv(\"./ind_nifty50list.csv\")\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ind_stock in all_equity_lst['SYMBOL']:\n",
    "    stock_list.append(ind_stock)\n",
    "\n",
    "print(\"Inside Stock_List:\",stock_list)\n",
    "\n",
    "sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "table_trun_conn = sql_engine.connect()\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS market_smith_stock_eval_test\")\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS all_stocks_quarterly_earnings_test\")\n",
    "sql_engine.execute(\"DROP TABLE IF EXISTS market_smith_stock_institutional_data_test\")\n",
    "table_trun_conn.close()\n",
    "\n",
    "#Below code part is used to iterate every set of 10 stocks \n",
    "counter = 0\n",
    "top_stock = ''\n",
    "while (counter <= len(stock_list)):\n",
    "    time.sleep(4)\n",
    "    if(counter!=0):\n",
    "        sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "        db_conn= sql_engine.connect()\n",
    "        top_stock = str(pd.read_sql_query(con = db_conn ,sql='select top 1 [stock_name] From market_smith_stock_eval_test order by stock_name desc'))\n",
    "        db_conn.close()\n",
    "    \n",
    "#Calling webscraping function\n",
    "    if(stock_list[counter] != top_stock):\n",
    "        marketsmith_scrape(stock_list[counter:10+ counter])\n",
    "        counter = counter + 10\n",
    "        print('Next Iteration on WHILE LOOP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading CSV file to fetch all listed NSE Stocks from local folder\n",
    "all_equity_lst = pd.read_csv(\"./NSE_EQUITY_List.csv\")\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ind_stock in all_equity_lst['SYMBOL']:\n",
    "    stock_list.append(ind_stock)\n",
    "\n",
    "print(\"Inside Stock_List:\",stock_list)\n",
    "\n",
    "#Inserting stock data into SQL database using sqlachemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sql_engine = create_engine('mssql+pyodbc://' + \"DESKTOP-EQ55Q8H\" + '/' + \"NSEBhavcopy\" + '?trusted_connection=yes&driver=SQL+Server')\n",
    "\n",
    "db_conn= sql_engine.connect()\n",
    "\n",
    "sql_res = pd.read_sql_query(con = db_conn ,sql='select top 1 [stock_name] From market_smith_stock_eval order by stock_name desc')\n",
    "\n",
    "print(\"Last Stock Data in Table\",sql_res)\n",
    "\n",
    "db_conn.close()\n",
    "\n",
    "print(\"Index of Result\",stock_list[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
